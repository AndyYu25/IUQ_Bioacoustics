{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd051720",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install blitz-bayesian-pytorch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de58e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "project_path = \"/content/drive/MyDrive/IUQ_Bioacoustics\"\n",
    "sys.path.append(project_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf1739",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from blitz.modules import BayesianLinear\n",
    "from blitz.utils import variational_estimator\n",
    "from blitz.losses import kl_divergence_from_nn\n",
    "from dataset import create_datasets\n",
    "from baseline_model import MarineMammalBNN\n",
    "import numpy as np\n",
    "\n",
    "root_dir = f\"{project_path}/data/preprocessed\"\n",
    "train_dataset, test_dataset, class_to_idx = create_datasets(\n",
    "    root_dir=root_dir,\n",
    "    test_size=0.2,\n",
    "    min_samples=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "class_weights = train_dataset.get_class_weights()\n",
    "NUM_CLASSES = len(class_to_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2fa3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = MarineMammalBNN(num_classes=NUM_CLASSES).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "print(\"kl_loss exists:\", hasattr(model, \"kl_loss\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e7414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def elbo_loss(model, x, y, criterion, kl_weight):\n",
    "    pred = model(x)\n",
    "    ce = criterion(pred, y)\n",
    "    kl = kl_divergence_from_nn(model)\n",
    "    return ce + kl_weight * kl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299cce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 20\n",
    "KL_WEIGHT = 0.01\n",
    "\n",
    "model.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = elbo_loss(model, x, y, criterion, KL_WEIGHT)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962ade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{project_path}/marine_bnn.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef41f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_with_uncertainty(model, x, n_samples=30):\n",
    "    model.eval()\n",
    "    preds = [model(x.to(device)).softmax(dim=1).detach() for _ in range(n_samples)]\n",
    "    stacked = torch.stack(preds)\n",
    "    return stacked.mean(dim=0), stacked.std(dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correct_list = []\n",
    "confidence_list = []\n",
    "entropy_list = []\n",
    "std_list = []\n",
    "\n",
    "for x, y in test_loader:\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    mean_pred, std_pred = predict_with_uncertainty(model, x, n_samples=30)\n",
    "    pred_label = mean_pred.argmax(dim=1).item()\n",
    "    true_label = y.item()\n",
    "    confidence = mean_pred.max().item()\n",
    "    entropy = -torch.sum(mean_pred * torch.log(mean_pred + 1e-8)).item()\n",
    "    std = std_pred.max().item()\n",
    "    correct = int(pred_label == true_label)\n",
    "\n",
    "    correct_list.append(correct)\n",
    "    confidence_list.append(confidence)\n",
    "    entropy_list.append(entropy)\n",
    "    std_list.append(std)\n",
    "\n",
    "mean_accuracy = np.mean(correct_list)\n",
    "mean_confidence = np.mean(confidence_list)\n",
    "mean_entropy = np.mean(entropy_list)\n",
    "mean_std = np.mean(std_list)\n",
    "\n",
    "print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
    "print(f\"Mean Predictive Confidence: {mean_confidence:.4f}\")\n",
    "print(f\"Mean Predictive Entropy: {mean_entropy:.4f}\")\n",
    "print(f\"Mean Predictive Std: {mean_std:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
